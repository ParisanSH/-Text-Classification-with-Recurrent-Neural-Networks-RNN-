{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import string\n","import collections\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-27T10:44:48.759982Z","iopub.execute_input":"2022-05-27T10:44:48.760310Z","iopub.status.idle":"2022-05-27T10:44:48.765338Z","shell.execute_reply.started":"2022-05-27T10:44:48.760260Z","shell.execute_reply":"2022-05-27T10:44:48.764544Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, SimpleRNN, Embedding\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"execution":{"iopub.status.busy":"2022-05-27T10:44:48.794841Z","iopub.execute_input":"2022-05-27T10:44:48.795418Z","iopub.status.idle":"2022-05-27T10:44:48.801476Z","shell.execute_reply.started":"2022-05-27T10:44:48.795384Z","shell.execute_reply":"2022-05-27T10:44:48.800592Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class Dataset(): \n","    def __init__(self, dataset_path, stopword_path):\n","        self.dataframe = pd.read_csv(dataset_path, encoding=\"Latin-1\")\n","        self.stopwords = pd.read_csv(stopword_path, header = None)\n","        \n","        self.dataframe['sentiment']= self.dataframe['sentiment'].map({'positive': 1, 'negative': 0})\n","        \n","        self.dataframe['clean_msg']= self.dataframe['review'].apply(lambda x: self.remove_punctuation(x))\n","        \n","        self.dataframe['clean_msg']= self.dataframe['clean_msg'].apply(lambda x: x.lower())\n","        \n","        self.dataframe['clean_msg']= self.dataframe['clean_msg'].apply(lambda x: self.tokenization(x))\n","        \n","        self.dataframe['clean_msg']= self.dataframe['clean_msg'].apply(lambda x: self.remove_stopwords(x))\n","        \n","        self.dataframe['clean_msg']= self.dataframe['clean_msg'].apply(lambda x: self.remove_short_word(x))\n","        \n","        self.dataframe['lens'] = self.dataframe['clean_msg'].apply(lambda x: len(x))\n","        self.max_sentence = self.dataframe['lens'].max()\n","        \n","        # create dictionary of words\n","        self.list_review = self.dataframe['clean_msg'].to_list()\n","        self.list_words = self.create_dictionary(self.list_review)\n","        del self.list_review\n","        self.len_words = len(self.list_words)\n","        \n","        # indexing (convert strings to intgers)\n","        a = self.dataframe['clean_msg'].explode()\n","        a[:] = a.factorize()[0]\n","        a = a.apply(lambda x:x+1)\n","        self.dataframe['indexs'] = a.groupby(level=0).agg(list)\n","        del a\n","        \n","        # pre padding with zero(0)\n","        self.pad = pad_sequences(self.dataframe['indexs'].to_list(), maxlen=self.max_sentence)\n","        self.len_words += 1\n","        \n","        # split data test & train\n","        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.pad, self.dataframe['sentiment'], test_size=0.20, random_state=42)\n","        \n","        # remove self.dataframe to avoid storing data too much\n","        del self.dataframe\n","        \n","        \n","    def remove_punctuation(self, text):\n","        punctuation_free = \"\".join([i if i not in string.punctuation else ' ' for i in text])\n","        return punctuation_free\n","    \n","    def tokenization(self, text):\n","        tokens = str(text).split()\n","        return tokens\n","\n","    def remove_short_word(self, text):\n","        short_word_free = [i for i in text if len(i) > 2]\n","        return short_word_free\n","        \n","    def remove_stopwords(self, text):\n","        stoplist = self.stopwords[0].to_list()\n","        output= [i for i in text if i not in stoplist]\n","        return output\n","    \n","    def create_dictionary(self, sentences):\n","        total_dictionary = {}\n","        total_words = []\n","        for index in range(len(sentences)):\n","            words_cnt = collections.Counter(sentences[index])\n","            for word in words_cnt:\n","                cnt = words_cnt[word]\n","                # check if word has already added to total_dictionary\n","                if word in total_dictionary.keys():\n","                    total_dictionary[word] += cnt\n","                else:\n","                    total_words.append(word)\n","                    total_dictionary[word] = cnt\n","        \n","        return total_words\n","        "],"metadata":{"execution":{"iopub.status.busy":"2022-05-27T10:44:48.878812Z","iopub.execute_input":"2022-05-27T10:44:48.879458Z","iopub.status.idle":"2022-05-27T10:44:48.906874Z","shell.execute_reply.started":"2022-05-27T10:44:48.879384Z","shell.execute_reply":"2022-05-27T10:44:48.905949Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["data = Dataset('../input/imdb-da/IMDB_Dataset.csv', '../input/imdb-da/stopwords.txt')"],"metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-27T10:44:48.908383Z","iopub.execute_input":"2022-05-27T10:44:48.908794Z","iopub.status.idle":"2022-05-27T10:44:53.843943Z","shell.execute_reply.started":"2022-05-27T10:44:48.908758Z","shell.execute_reply":"2022-05-27T10:44:53.842896Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["data.X_train.shape, data.X_test.shape"],"metadata":{"execution":{"iopub.status.busy":"2022-05-27T10:44:53.846004Z","iopub.execute_input":"2022-05-27T10:44:53.846474Z","iopub.status.idle":"2022-05-27T10:44:53.854308Z","shell.execute_reply.started":"2022-05-27T10:44:53.846424Z","shell.execute_reply":"2022-05-27T10:44:53.853611Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"((4000, 897), (1000, 897))"},"metadata":{}}]},{"cell_type":"code","source":["# print(sorted(data.stopwords[0].to_list()))"],"metadata":{"execution":{"iopub.status.busy":"2022-05-27T10:44:53.856010Z","iopub.execute_input":"2022-05-27T10:44:53.856716Z","iopub.status.idle":"2022-05-27T10:44:53.867247Z","shell.execute_reply.started":"2022-05-27T10:44:53.856636Z","shell.execute_reply":"2022-05-27T10:44:53.866103Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class Many_to_one_Elman_Net():\n","    def __init__(self, dataset, max_vocab, max_len):\n","        self.max_vocab = max_vocab\n","        self.max_len = max_len\n","    \n","        self.y_train = dataset.y_train\n","        self.y_test = dataset.y_test\n","        self.trainX = dataset.X_train\n","        self.testX = dataset.X_test\n","    \n","    def RNN_model(self, hidden_neurons, dense_neurons, hidden_act, dense_act,\n","                  loss_func, optimizer_func):\n","        \n","        model = Sequential()\n","        model.add(Embedding(input_dim=self.max_vocab, output_dim=hidden_neurons,\n","                            input_length=self.max_len))\n","        model.add(SimpleRNN(units=hidden_neurons, activation=hidden_act))\n","        model.add(Dense(units=dense_neurons, activation=dense_act))\n","        model.compile(loss=loss_func, optimizer=optimizer_func, metrics=['acc']) \n","        return model\n","    \n","    def train(self, epochs, batch_size, verbose):\n","        # optimizer = 'rmsprop', 'adam'\n","        # loss = 'binary_crossentropy', 'mean_squared_error'\n","        self.model = self.RNN_model(hidden_neurons=64, dense_neurons=1,\n","                                     hidden_act='sigmoid', dense_act='sigmoid',\n","                                     loss_func='mean_squared_error',\n","                                     optimizer_func='rmsprop') \n","                \n","        self.model.fit(self.trainX, self.y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","        return self.model\n","    \n","    def predict(self):\n","        train_predict = self.model.predict(self.trainX)\n","        test_predict = self.model.predict(self.testX)\n","        return train_predict, test_predict\n","    \n","    def evaluate(self):\n","        acc_train = self.model.evaluate(self.trainX, self.y_train)\n","        acc_test = self.model.evaluate(self.testX, self.y_test)\n","        return acc_train[1], acc_test[1]"],"metadata":{"execution":{"iopub.status.busy":"2022-05-27T10:44:53.869724Z","iopub.execute_input":"2022-05-27T10:44:53.870623Z","iopub.status.idle":"2022-05-27T10:44:53.884971Z","shell.execute_reply.started":"2022-05-27T10:44:53.870577Z","shell.execute_reply":"2022-05-27T10:44:53.884196Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["elman = Many_to_one_Elman_Net(data, data.len_words, data.max_sentence)\n","elman.train(epochs=15, batch_size=100, verbose=1)\n","print(elman.model.summary())\n"],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-27T10:44:53.886538Z","iopub.execute_input":"2022-05-27T10:44:53.887069Z","iopub.status.idle":"2022-05-27T10:49:50.915145Z","shell.execute_reply.started":"2022-05-27T10:44:53.887021Z","shell.execute_reply":"2022-05-27T10:49:50.914388Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/15\n40/40 [==============================] - 22s 517ms/step - loss: 0.2610 - acc: 0.5140\nEpoch 2/15\n40/40 [==============================] - 20s 492ms/step - loss: 0.2432 - acc: 0.6093\nEpoch 3/15\n40/40 [==============================] - 20s 509ms/step - loss: 0.2277 - acc: 0.7195\nEpoch 4/15\n40/40 [==============================] - 20s 507ms/step - loss: 0.2059 - acc: 0.7895\nEpoch 5/15\n40/40 [==============================] - 19s 484ms/step - loss: 0.1781 - acc: 0.8205\nEpoch 6/15\n40/40 [==============================] - 20s 502ms/step - loss: 0.1470 - acc: 0.8395\nEpoch 7/15\n40/40 [==============================] - 19s 481ms/step - loss: 0.1174 - acc: 0.8610\nEpoch 8/15\n40/40 [==============================] - 20s 502ms/step - loss: 0.0914 - acc: 0.8870\nEpoch 9/15\n40/40 [==============================] - 19s 475ms/step - loss: 0.0692 - acc: 0.9105\nEpoch 10/15\n40/40 [==============================] - 20s 489ms/step - loss: 0.0519 - acc: 0.9302\nEpoch 11/15\n40/40 [==============================] - 20s 494ms/step - loss: 0.0360 - acc: 0.9578\nEpoch 12/15\n40/40 [==============================] - 19s 478ms/step - loss: 0.0244 - acc: 0.9720\nEpoch 13/15\n40/40 [==============================] - 20s 490ms/step - loss: 0.0167 - acc: 0.9833\nEpoch 14/15\n40/40 [==============================] - 19s 472ms/step - loss: 0.0120 - acc: 0.9858\nEpoch 15/15\n40/40 [==============================] - 20s 488ms/step - loss: 0.0082 - acc: 0.9908\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 897, 64)           2496128   \n_________________________________________________________________\nsimple_rnn_1 (SimpleRNN)     (None, 64)                8256      \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 2,504,449\nTrainable params: 2,504,449\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":["train_predict, test_predict = elman.predict()\n","acc_train, acc_test = elman.evaluate()"],"metadata":{"execution":{"iopub.status.busy":"2022-05-27T10:49:50.916108Z","iopub.execute_input":"2022-05-27T10:49:50.916366Z","iopub.status.idle":"2022-05-27T10:50:33.057364Z","shell.execute_reply.started":"2022-05-27T10:49:50.916338Z","shell.execute_reply":"2022-05-27T10:50:33.056555Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"125/125 [==============================] - 17s 130ms/step - loss: 0.0051 - acc: 0.9952\n32/32 [==============================] - 4s 129ms/step - loss: 0.2152 - acc: 0.7230\n","output_type":"stream"}]},{"cell_type":"code","source":["print('Train accuracy: ', acc_train*100)\n","print('Test accuracy:  ', acc_test*100)"],"metadata":{"execution":{"iopub.status.busy":"2022-05-27T10:52:10.683912Z","iopub.execute_input":"2022-05-27T10:52:10.684706Z","iopub.status.idle":"2022-05-27T10:52:10.689496Z","shell.execute_reply.started":"2022-05-27T10:52:10.684635Z","shell.execute_reply":"2022-05-27T10:52:10.688850Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Train accuracy:  99.52499866485596\nTest accuracy:   72.29999899864197\n","output_type":"stream"}]},{"cell_type":"code","source":["# lis = elman.model.get_weights()\n","# print(len(lis))\n","# for i in lis:\n","#     print(i.shape)"],"metadata":{"execution":{"iopub.status.busy":"2022-05-27T10:50:33.058927Z","iopub.execute_input":"2022-05-27T10:50:33.059542Z","iopub.status.idle":"2022-05-27T10:50:33.062959Z","shell.execute_reply.started":"2022-05-27T10:50:33.059507Z","shell.execute_reply":"2022-05-27T10:50:33.062259Z"},"trusted":true},"execution_count":29,"outputs":[]}]}